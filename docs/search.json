[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ADU blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nSkills Extraction with Large Language Models\n\n\n\n\n\n\n\nanalysis\n\n\n\n\nPrompt design and fine-tuning models with Hugging Face and OpenAI\n\n\n\n\n\n\nAug 10, 2023\n\n\nSean Greaves\n\n\n\n\n\n\n  \n\n\n\n\nDark Kitchen Cartography\n\n\n\n\n\n\n\nanalysis\n\n\n\n\nBuilding a UK-wide map of Deliveroo Editions\n\n\n\n\n\n\nJul 24, 2023\n\n\nSean Greaves\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Autonomy Data Unit",
    "section": "",
    "text": "Welcome to the ADU (Autonomy Data Unit) blog! Here we will post some outtakes of our quantitative research, tutorials, and general musings on tech and progressive politics.\nOur team:\n\nLukas Kikuchi      \nSonia Balagopalan      \nLuiz Garcia    \nSean Greaves      \nRowan Trickett"
  },
  {
    "objectID": "posts/editions/dark_kitchen_cartography.html",
    "href": "posts/editions/dark_kitchen_cartography.html",
    "title": "Dark Kitchen Cartography",
    "section": "",
    "text": "Dedicated sites for preparing takeaway meals for delivery only known as “dark kitchens” have become a widely adopted model in the food service industry throughout the past half decade. Dark kitchens enable a restaurant’s delivery business to be seperated from in-house business and operated from non-residential central locations where overhead and operating costs are reduced. Understanding the successes and failures of this service model could provide useful insights into emerging forms of economic planning, risk management, urban design and food distribution. However there is a lack of detailed data on the growth and current state of dark kitchens within the UK.\nTo the best of our knowledge, a map of the UK’s dark kitchen locations does not exist. Therefore we set out to make one for Deliveroo’s UK dark kitchen facilities, known as ‘Editions’, to better understand their growth and current state.\nDisclaimer: all data within this blog post was gathered before Wednesday 19th July 2023."
  },
  {
    "objectID": "posts/editions/dark_kitchen_cartography.html#locating-editions",
    "href": "posts/editions/dark_kitchen_cartography.html#locating-editions",
    "title": "Dark Kitchen Cartography",
    "section": "Locating Editions",
    "text": "Locating Editions\nDeliveroo Editions was launched in May 2017 as a ‘concept that puts an end to postcode food envy’. Initially trialed in Camberwell, Battersea, Dulwich and Canary Wharf, Deliveroo announced there ambition to scale to 30 locations across the UK within the first year. The Internet Archive’s Wayback Machine maintains a capture of the webpage for the original Deliveroo Editions announcement.\n\nTo find Editions restaurants we can add tags=deliveroo+editions as a query string when searching for restaurants near a given location. For example to find all the Editions partners delivering to Stepney Green, we can try: https://deliveroo.co.uk/restaurants/london/stepney-green?fulfillment_method=DELIVERY&tags=deliveroo+editions:\n\nIf we load the webpage for Popeyes Louisiana Kitchen, we can identify the restaurant is based at “Whitechapel Editions” from the location name in restaurant’s url: https://deliveroo.co.uk/menu/London/whitechapel-editions/popeyes-editions-wme/?day=today&geohash=gcpvngtckn3c&time=ASAP. Therefore the address for Popeyes Louisiana Kitchen is also the address for Whitechapel Editions which happens to be 10 Assembly Passage, London, E14UT, a 2-storey B-class office space with a disco ball included built in 1906 right next to the busy A11 road into central London.\n\nTo find all the other restaurants based at Whitechapel Editions (london/whitechapel-editions), we can search for Editions partners (tags=deliveroo+editions) nearby with the following url: https://deliveroo.co.uk/restaurants/london/whitechapel-editions?fulfillment_method=DELIVERY&tags=deliveroo+editions. We can deduce that all the restaurants based 0.0 miles away are those at the editions kitchen and can validate this by checking for whitechapel-editions in their urls.\n\nUsing this approach, we can trawl the Internet Archive for Deliveroo’s historic data and explore the possibility of charting the growth of Editions since 2017."
  },
  {
    "objectID": "posts/editions/dark_kitchen_cartography.html#historic-editions-data",
    "href": "posts/editions/dark_kitchen_cartography.html#historic-editions-data",
    "title": "Dark Kitchen Cartography",
    "section": "Historic Editions Data",
    "text": "Historic Editions Data\nDeliveroo’s website has been archived many times by the Wayback Machine. Some of the captured webpages include search results specific to UK locations with Deliveroo Editions filters. Unfortunately only 46 webpages with Editions search results could be retrieved, each of which was captured between 1 and 5 times over a period of 2 years. This data is likely too sparse to allow for detailed analysis of the growth of Editions in the UK. However the data has some utility in providing an incomplete historic list of Editions partners between 2020 and 2022.\n\nBy iterating through every capture extracting the restaurant names, restaurant urls, editions and timestamps, we can build a dataset of over 500 Editions partners:\n\n\n\n\n\n\n\n\n\nname\nlocation\ntimestamps\ntimestamp_urls\nrestaurant_url\n\n\n\n\n0\nOowee Vegan\nbrighton-editions\n['20201019', '20201021']\n['https://web.archive.org/web/20201019/https:/...\nhttps://deliveroo.co.uk/menu/brighton/brighton...\n\n\n1\nShake Shack\nbrighton-editions\n['20201019', '20201021']\n['https://web.archive.org/web/20201019/https:/...\nhttps://deliveroo.co.uk/menu/brighton/brighton...\n\n\n2\nLost Boys Chicken\nhove\n['20201019', '20210618', '20210123', '20201021...\n['https://web.archive.org/web/20201019/https:/...\nhttps://deliveroo.co.uk/menu/brighton/hove/los...\n\n\n3\nThe Athenian\nbrighton-editions\n['20201019', '20210618', '20210123', '20201021...\n['https://web.archive.org/web/20201019/https:/...\nhttps://deliveroo.co.uk/menu/brighton/brighton...\n\n\n4\nThe Great British Cheesecake Company\nbrighton-editions\n['20201019', '20210618', '20210123', '20210511...\n['https://web.archive.org/web/20201019/https:/...\nhttps://deliveroo.co.uk/menu/brighton/brighton...\n\n\n\n\n\n\n\nWhilst mapping the growth of Editions with historic data remains an elusive goal, we can look to present day data to build a map of Editions in the UK in its current state."
  },
  {
    "objectID": "posts/editions/dark_kitchen_cartography.html#present-day-editions-data",
    "href": "posts/editions/dark_kitchen_cartography.html#present-day-editions-data",
    "title": "Dark Kitchen Cartography",
    "section": "Present-Day Editions Data",
    "text": "Present-Day Editions Data\nMany of Deliveroo’s well known Editions locations can be found by searching the Food Standards Agency (FSA) for businesses containing “Deliveroo” in their title. Deliveroo requires its restaurants to have an FSA rating of at least 2 to use the platform. Deliveroo advertises Editions as going above and beyond these minimal requirements, maintaining the highest possible hygiene ratings across all of its sites. This is a far cry from the poor hygiene practices and lack of regulation associated with the original ‘ghost kitchens’ of New York that advertised through Grubhub and attracted media attention in 2015.\n\nWe can cross reference 16 of these businesses with editions names encountered from searching Deliveroo’s site:\n\n\n\n\n\n\n\n\n\nEditions Name\nFSA Business\nAddress\n\n\n\n\n0\nbsy-2-editions\nDeliveroo sp ltd\n145 Ormside Street London SE15 1TF\n\n\n1\nhonor-oak-park\nDeliveroo SP Ltd\nUnits 3-4 Dulwich Business Centre Malham Road ...\n\n\n2\nculvert-place-editions\nDeliveroo\nUnit 2 Editions Battersea 15a Parkfield Indust...\n\n\n3\nwandsworth-editions\nDeliveroo SP Ltd\nUnit 4 271 Merton Road London SW18 5JS\n\n\n4\ncanning-town-editions\nDeliveroo SP Ltd\nUnit 3 Crescent Court Business Centre 4C North...\n\n\n5\nmaida-vale-editions\nDeliveroo Hop Ltd\nUnit 24 Mitre Bridge Industrial Park Mitre Way...\n\n\n6\ncaledonian-road-and-barnsbury\nDeliveroo\nDeliveroo Unit 4 Roman Way Industrial Estate 1...\n\n\n7\nbrent-cross-editions\nDeliveroo SP Ltd\n2 Phoenix Industrial Estate Apsley Way London ...\n\n\n8\nhornsey-station\nDeliveroo SP Ltd\nUnit 21 Cranford Way Hornsey London N8 9DG\n\n\n9\ncambridge-editions\nDeliveroo\nUnit 3-4 Restwell House Coldhams Road Cambridg...\n\n\n10\njubilee-park-lee-valley\nDeliveroo SP Ltd\nUnit 6 Great Cambridge Industrial Estate Linco...\n\n\n11\nglasgow-editions\nDeliveroo SP Ltd\n1 Scotland Street Glasgow G5 8LS\n\n\n12\neditions-in-leeds\nDeliveroo Editions\nUnit 1 Scott Hall Mills Scott Hall Street Mean...\n\n\n13\nnottingham-editions\nDeliveroo SP Ltd\nUnit 1 Redwood Court Salisbury Street Nottingh...\n\n\n14\nbrighton-and-hove-editions\nDeliveroo Editions\nUnit 1 Saxon Works 22 Olive Road Hove BN3 7GY\n\n\n15\nbristol-editions-site\nDeliveroo SP Ltd\nUnit 1 Glenfrome House Eastgate Road Eastville...\n\n\n\n\n\n\n\nHowever there are many Editions partners that do not operate from any of these sites. Here is a handful of examples:\n\nLuxford Burgers, Sabor & Bulked - Loaded Fries (Broughton)\nSprigg - Ingram Street (Glasgow City Centre)\nPasta Evangelists (Wortley)\n\nTo get all of the Editions partners in the UK at any one time we can search Deliveroo with a postcode from each of the ~2900 postcode districts in the UK. Whilst this brute force approach is relatively inefficient given that Deliveroo is not operating at most UK postcodes outside of cities and large towns, it does offer a near-complete picture of Deliveroo’s operations in the UK and most of the Editions partners."
  },
  {
    "objectID": "posts/editions/dark_kitchen_cartography.html#mapping-deliveroo-editions",
    "href": "posts/editions/dark_kitchen_cartography.html#mapping-deliveroo-editions",
    "title": "Dark Kitchen Cartography",
    "section": "Mapping Deliveroo Editions",
    "text": "Mapping Deliveroo Editions\nBy searching all of the Deliveroo restaurants delivering to postcodes within each of the UK’s ~2900 postcode districts, 238 editions partners were identified across 53 addresses and 12 regions:\n\n\n\n        \n        \n\n\n\n\n\n\n\n\n\n\n\nname\nlocation\nedition\nrestaurant_url\naddress\nlat\nlon\n\n\n\n\n0\nYacob's Kitchen\nLondon\nbsy-1-editions\nhttps://deliveroo.co.uk/menu/London/bsy-1-edit...\nUnit 9, British Wharf, Landmann Way, London, S...\n51.484623\n-0.044459\n\n\n1\nShake Shack\nLondon\nbsy-1-editions\nhttps://deliveroo.co.uk/menu/London/bsy-1-edit...\nUnit 9, British Wharf, Landmann Way, London, S...\n51.484623\n-0.044459\n\n\n2\nPoke Shack\nLondon\nbsy-1-editions\nhttps://deliveroo.co.uk/menu/London/bsy-1-edit...\nUnit 9, British Wharf, Landmann Way, London, S...\n51.484623\n-0.044459\n\n\n3\nDishoom\nLondon\nbsy-2-editions\nhttps://deliveroo.co.uk/menu/London/bsy-2-edit...\n145 Ormside Street, South Bermondsey, London, ...\n51.483107\n-0.055627\n\n\n4\nWING·STOP\nLondon\nbsy-2-editions\nhttps://deliveroo.co.uk/menu/London/bsy-2-edit...\n145 Ormside Street, London, SE151TF\n51.483107\n-0.055627\n\n\n\n\n\n\n\nWingstop (2021 Deliveroo Restaurant of the Year winner), Dishoom (2021 Deliveroo Best Indian Restaurant winner) and the Athenian appear to be the most scalable partners appearing in 6+ Editions across the UK. Editions sites also include popular partners that don’t offer cooked food like the Californian CBD drinks vendors ‘Trip CBD Store’ and Ben & Jerry’s.\n\n\n\n\n\n\nLondon is the region containing the most dark kitchens with 32 editions facilities compared to the 21 locations spread across all other regions of the UK:\n\n\n\n\n\nLondon also offers the greatest choice of Editions partners at 127 compared to the 112 vendors spread across the other Editions sites.\n\n\n\n\n\nThe Editions site with the most partners is in Leeds with 22 vendors under one roof at 1 Scott Hall Street:"
  },
  {
    "objectID": "posts/editions/index.html",
    "href": "posts/editions/index.html",
    "title": "Dark Kitchen Cartography",
    "section": "",
    "text": "Dedicated sites for preparing takeaway meals for delivery-only known as “dark kitchens” have been widely adopted across the food service industry throughout the past half decade. Dark kitchens enable restaurants to seperate their delivery business from in-house business and operate from non-residential central locations where overhead and operating costs are reduced. Understanding the successes and failures of this service model could provide useful insights into emerging forms of economic planning, risk management, urban design and food distribution. However there is a lack of detailed data on the growth and current state of dark kitchens within the UK.\nTo the best of our knowledge, a map of the UK’s dark kitchen locations does not exist. Therefore we set out to make one for Deliveroo’s UK dark kitchen facilities, known as ‘Editions’, to better understand their growth and current state.\nDisclaimer: all data within this blog post was gathered before Wednesday 19th July 2023."
  },
  {
    "objectID": "posts/editions/index.html#locating-editions",
    "href": "posts/editions/index.html#locating-editions",
    "title": "Dark Kitchen Cartography",
    "section": "Locating Editions",
    "text": "Locating Editions\nDeliveroo Editions launched in May 2017 as a concept to put ‘an end to postcode food envy’. Initially trialed in Camberwell, Battersea, Dulwich and Canary Wharf, Deliveroo announced there ambition to scale to 30 locations across the UK within the first year. The Internet Archive’s Wayback Machine maintains a capture of the webpage for the original Deliveroo Editions announcement.\n\nTo find restaurants using Deliveroo’s dark kitchens, known as Editions partners, we can add tags=deliveroo+editions as a query string when searching for restaurants near a given location. For example to find all the Editions partners delivering to Stepney Green, we can try: https://deliveroo.co.uk/restaurants/london/stepney-green?fulfillment_method=DELIVERY&tags=deliveroo+editions:\n\nIf we load the webpage for Popeyes Louisiana Kitchen, we can identify the partner is based at “Whitechapel Editions” from the location name in restaurant’s url: https://deliveroo.co.uk/menu/London/whitechapel-editions/popeyes-editions-wme/?day=today&geohash=gcpvngtckn3c&time=ASAP. Therefore the address for Popeyes Louisiana Kitchen is also the address for Whitechapel Editions which happens to be 10 Assembly Passage, London, E14UT, a 2-storey B-class office space with a disco ball included built in 1906 right next to the busy A11 road into central London.\n\nTo find all the other partners based at Whitechapel Editions (london/whitechapel-editions), we can search for Editions partners (tags=deliveroo+editions) nearby with the following url: https://deliveroo.co.uk/restaurants/london/whitechapel-editions?fulfillment_method=DELIVERY&tags=deliveroo+editions. We can deduce that all the restaurants based 0.0 miles away are those at the Editions kitchen and can validate this by checking for whitechapel-editions in their urls.\n\nUsing this approach, we can trawl the Internet Archive for Deliveroo’s historic data and explore the possibility of charting the growth of Editions since 2017."
  },
  {
    "objectID": "posts/editions/index.html#historic-editions-data",
    "href": "posts/editions/index.html#historic-editions-data",
    "title": "Dark Kitchen Cartography",
    "section": "Historic Editions Data",
    "text": "Historic Editions Data\nDeliveroo’s website has been archived many times by the Wayback Machine. Some of the captured webpages include search results specific to UK locations with Deliveroo Editions filters. Unfortunately only 46 webpages with Editions search results could be retrieved, each of which was captured between 1 and 5 times over a period of 2 years. This data is likely too sparse to allow for detailed analysis of the growth of Editions in the UK. However the data has some utility in providing an incomplete historic list of Editions partners between 2020 and 2022.\n\nBy iterating through every capture extracting the restaurant names, restaurant urls, Editions and timestamps, we can build a dataset of over 500 Editions partners:\n\n\n\n\n\n\n\n\n\nname\nlocation\ntimestamps\ntimestamp_urls\nrestaurant_url\n\n\n\n\n0\nOowee Vegan\nbrighton-editions\n['20201019', '20201021']\n['https://web.archive.org/web/20201019/https:/...\nhttps://deliveroo.co.uk/menu/brighton/brighton...\n\n\n1\nShake Shack\nbrighton-editions\n['20201019', '20201021']\n['https://web.archive.org/web/20201019/https:/...\nhttps://deliveroo.co.uk/menu/brighton/brighton...\n\n\n2\nLost Boys Chicken\nhove\n['20201019', '20210618', '20210123', '20201021...\n['https://web.archive.org/web/20201019/https:/...\nhttps://deliveroo.co.uk/menu/brighton/hove/los...\n\n\n3\nThe Athenian\nbrighton-editions\n['20201019', '20210618', '20210123', '20201021...\n['https://web.archive.org/web/20201019/https:/...\nhttps://deliveroo.co.uk/menu/brighton/brighton...\n\n\n4\nThe Great British Cheesecake Company\nbrighton-editions\n['20201019', '20210618', '20210123', '20210511...\n['https://web.archive.org/web/20201019/https:/...\nhttps://deliveroo.co.uk/menu/brighton/brighton...\n\n\n\n\n\n\n\nWhilst mapping the growth of Editions with historic data remains an elusive goal, we can look to present day data to build a map of Editions in the UK in its current state."
  },
  {
    "objectID": "posts/editions/index.html#present-day-editions-data",
    "href": "posts/editions/index.html#present-day-editions-data",
    "title": "Dark Kitchen Cartography",
    "section": "Present-Day Editions Data",
    "text": "Present-Day Editions Data\nMany of Deliveroo’s well known Editions locations can be found by searching the Food Standards Agency (FSA) for businesses containing “Deliveroo” in their title. Deliveroo requires its restaurants to have an FSA rating of at least 2 to use the platform. Deliveroo advertises Editions as going above and beyond these minimal requirements, maintaining the highest possible hygiene ratings across all of its sites. This is a far cry from the poor hygiene practices and lack of regulation associated with the original ‘ghost kitchens’ of New York that advertised through Grubhub and attracted media attention in 2015.\n\nWe can cross reference 16 of these businesses with Editions locations encountered from searching Deliveroo’s site:\n\n\n\n\n\n\n\n\n\nEditions Name\nFSA Business\nAddress\n\n\n\n\n0\nbsy-2-editions\nDeliveroo sp ltd\n145 Ormside Street London SE15 1TF\n\n\n1\nhonor-oak-park\nDeliveroo SP Ltd\nUnits 3-4 Dulwich Business Centre Malham Road ...\n\n\n2\nculvert-place-editions\nDeliveroo\nUnit 2 Editions Battersea 15a Parkfield Indust...\n\n\n3\nwandsworth-editions\nDeliveroo SP Ltd\nUnit 4 271 Merton Road London SW18 5JS\n\n\n4\ncanning-town-editions\nDeliveroo SP Ltd\nUnit 3 Crescent Court Business Centre 4C North...\n\n\n5\nmaida-vale-editions\nDeliveroo Hop Ltd\nUnit 24 Mitre Bridge Industrial Park Mitre Way...\n\n\n6\ncaledonian-road-and-barnsbury\nDeliveroo\nDeliveroo Unit 4 Roman Way Industrial Estate 1...\n\n\n7\nbrent-cross-editions\nDeliveroo SP Ltd\n2 Phoenix Industrial Estate Apsley Way London ...\n\n\n8\nhornsey-station\nDeliveroo SP Ltd\nUnit 21 Cranford Way Hornsey London N8 9DG\n\n\n9\ncambridge-editions\nDeliveroo\nUnit 3-4 Restwell House Coldhams Road Cambridg...\n\n\n10\njubilee-park-lee-valley\nDeliveroo SP Ltd\nUnit 6 Great Cambridge Industrial Estate Linco...\n\n\n11\nglasgow-editions\nDeliveroo SP Ltd\n1 Scotland Street Glasgow G5 8LS\n\n\n12\neditions-in-leeds\nDeliveroo Editions\nUnit 1 Scott Hall Mills Scott Hall Street Mean...\n\n\n13\nnottingham-editions\nDeliveroo SP Ltd\nUnit 1 Redwood Court Salisbury Street Nottingh...\n\n\n14\nbrighton-and-hove-editions\nDeliveroo Editions\nUnit 1 Saxon Works 22 Olive Road Hove BN3 7GY\n\n\n15\nbristol-editions-site\nDeliveroo SP Ltd\nUnit 1 Glenfrome House Eastgate Road Eastville...\n\n\n\n\n\n\n\nHowever there are many Editions partners that do not operate from any of these addresses. Here is a handful of examples:\n\nLuxford Burgers, Sabor & Bulked - Loaded Fries (Broughton)\nSprigg - Ingram Street (Glasgow City Centre)\nPasta Evangelists (Wortley)\n\nTo get all of the Editions partners in the UK at any one time we can search Deliveroo with a postcode from each of the ~2900 postcode districts in the UK. Whilst this brute force approach is relatively inefficient given that Deliveroo is not operating at most UK postcodes outside of cities and large towns, it does offer a near-complete picture of Deliveroo’s operations in the UK and most of the Editions partners."
  },
  {
    "objectID": "posts/editions/index.html#mapping-deliveroo-editions",
    "href": "posts/editions/index.html#mapping-deliveroo-editions",
    "title": "Dark Kitchen Cartography",
    "section": "Mapping Deliveroo Editions",
    "text": "Mapping Deliveroo Editions\nBy searching all of the Deliveroo restaurants delivering to postcodes within each of the UK’s ~2900 postcode districts, 238 Editions partners were identified across 53 addresses and 12 regions:\n\n\n\n        \n        \n\n\n\n\n\n\n\n\n\n\n\nname\nlocation\nedition\nrestaurant_url\naddress\nlat\nlon\n\n\n\n\n0\nYacob's Kitchen\nLondon\nbsy-1-editions\nhttps://deliveroo.co.uk/menu/London/bsy-1-edit...\nUnit 9, British Wharf, Landmann Way, London, S...\n51.484623\n-0.044459\n\n\n1\nShake Shack\nLondon\nbsy-1-editions\nhttps://deliveroo.co.uk/menu/London/bsy-1-edit...\nUnit 9, British Wharf, Landmann Way, London, S...\n51.484623\n-0.044459\n\n\n2\nPoke Shack\nLondon\nbsy-1-editions\nhttps://deliveroo.co.uk/menu/London/bsy-1-edit...\nUnit 9, British Wharf, Landmann Way, London, S...\n51.484623\n-0.044459\n\n\n3\nDishoom\nLondon\nbsy-2-editions\nhttps://deliveroo.co.uk/menu/London/bsy-2-edit...\n145 Ormside Street, South Bermondsey, London, ...\n51.483107\n-0.055627\n\n\n4\nWING·STOP\nLondon\nbsy-2-editions\nhttps://deliveroo.co.uk/menu/London/bsy-2-edit...\n145 Ormside Street, London, SE151TF\n51.483107\n-0.055627\n\n\n\n\n\n\n\nWingstop (2021 Deliveroo Restaurant of the Year winner), Dishoom (2021 Deliveroo Best Indian Restaurant winner) and the Athenian appear to be the most scalable partners appearing in 6+ Editions across the UK. Editions sites also include popular partners that don’t offer cooked food like the Californian CBD drinks vendors ‘Trip CBD Store’ and Ben & Jerry’s.\n\n\n\n\n\n\nLondon is the region containing the most dark kitchens with 32 Editions sites compared to the 21 locations spread across all other regions of the UK:\n\n\n\n\n\nLondon also offers the greatest choice of Editions partners at 127 compared to the 112 vendors spread across the other Editions sites.\n\n\n\n\n\nThe Editions site with the most partners is in Leeds with 22 partners under one roof at 1 Scott Hall Street:"
  },
  {
    "objectID": "posts/skills/skills_extraction.html",
    "href": "posts/skills/skills_extraction.html",
    "title": "Skills Extraction with Large Language Models",
    "section": "",
    "text": "Skills extraction is a well explored task in natural language processing often applied to job ads and employment data to quantify the supply and demand of skills within a population. Skills extraction can help authorities aquire rich localised labour market data to inform policy. Such data can play an important role in planning for transitions such as ensuring the UK has the neccessary skills in place to retrofit the nation’s housing stock to meet net-zero targets. Having the right composition of skills can mitigate the negative impacts of skills mismatches which can occur in both a surplus of skills, such as too many university graduates looking for high-quality roles, as well as shortages in skills like the supposed dearth of UK tech talent in 2023.\nIn this post we will test drive some recent approaches to skills extraction using large language models. We prioritise approaches that are accessible, relatively low cost and can be tested fairly quickly. We are motivated by existing work applying LLMs to skills extraction such as Nesta’s taxonomies of UK skills."
  },
  {
    "objectID": "posts/skills/skills_extraction.html#token-classification",
    "href": "posts/skills/skills_extraction.html#token-classification",
    "title": "Skills Extraction with Large Language Models",
    "section": "1. Token Classification",
    "text": "1. Token Classification\nSkills extraction can be approached as a named entity recognition task where we train models to label sequences of words that correspond to skills. This approach does require quality labelled datasets that can be time-consuming to build and difficult to source. The highest quality open dataset with skill annotations that we could get our hands on is ‘Skillspan’ from Zhang et al. (2022) consisting of 265 annotated English language job profiles (14.5K sentences and over 12.5K annotated spans) for hard and soft skills. This excellent resource is released alongside a codebase and paper ‘SkillSpan: Hard and Soft Skill Extraction from Job Postings’ in which the researchers report performance benchmarks for several transformer models fine-tuned on SkillSpan. Furthermore, the paper includes the extensive annotation guidelines used by the researchers to label the SkillSpan dataset, giving an insight into how time-consuming this task most likely was.\nThe data in SkillSpan is seperated into sentences labelled in the CoNNL format which looks like this:\n\n\n\nWord\nSkill\n\n\n\n\nThe\nO\n\n\ncandidate\nO\n\n\nshould\nO\n\n\nbe\nO\n\n\ncompetant\nO\n\n\nprogramming\nB-Skill\n\n\nin\nI-Skill\n\n\nPython\nI-Skill\n\n\n,\nO\n\n\nmentoring\nB-Skill\n\n\njunior\nI-Skill\n\n\ncollegues\nI-Skill\n\n\nand\nO\n\n\npresenting\nB-Skill\n\n\nto\nI-Skill\n\n\nleadership\nI-Skill\n\n\n\nWords are labelled ‘O’ if they are not part of a skill. The first word in a skill sequence is labelled B-Skill (b for beginning) and all proceeding words labelled I-Skill.\nWhen shopping for model architectures that might yield the best performance when fine-tuned on SkillSpan, we could look to roughly comparable datasets such as CoNLL 2003 and recent performance benchmarks. Models building on the BERT/RoBERTa architectures seem to do particularly well at entity recognition. This is because they are designed for bidirectional context understanding; understanding a word or phrase in the context of all the other words and phrases that surround it in a sentence. This is different to models like GPT-3/GPT-4 which are designed for unidirectional context understanding (left-to-right) which makes them excellent at generating human-like text but less effective at entity extraction out-the-box. We will attempt to benchmark SkillSpan on BERT and RoBERTa to see how feasible it is to fine-tune excellent skill extractors on consumer hardware with open data.\n\nTraining and Testing\nWe attempt to fine-tune BERT and RoBERTa on part of the SkillSpan dataset and compare performance with ‘JobBert’, a model released by the SkillSpan researchers pre-trained on 3.2M unlabeled job profile sentences. We fine-tuned our models on a V100 GPU (P3.2xlarge AWS EC2 instance) using a basic NBDev workflow. To access performance of the models, we evaluate them on the two open SkillSpan test sets known as HOUSE and TECH (comprised of job profiles from StackOverflow):\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel/Dataset\nPrecision (HOUSE)\nRecall (HOUSE)\nF1 (HOUSE)\nAccuracy (HOUSE)\nPrecision (TECH)\nRecall (TECH)\nF1 (TECH)\nAccuracy (TECH)\n\n\n\n\nBERT\n46.26\n45.90\n46.08\n93.50\n48.41\n53.17\n50.68\n94.91\n\n\nRoBERTa\n55.94\n49.05\n52.27\n93.84\n57.98\n54.04\n55.94\n95.24\n\n\nJobBERT\n52.22\n53.79\n52.99\n94.45\n50.22\n50.33\n50.27\n94.96\n\n\n\nWe notice a clear difference in performance between the subsets with RoBERTa outperforming on TECH and RoBERTa/JobBert performing better than BERT on HOUSE. RoBERTa achieves higher precision on both sets; getting a greater proportion of it’s labels correct. RoBERTa’s optimizations relative to JobBERT/BERT include training on a larger corpus of text and the use of dynamic masking which may have contributed to tangible improvements over the original BERT architectures. Differences in performance between JobBERT and BERT may be due to JobBERT being trained on a more relevant dataset of job profiles and fine-tuned on the full SkillSpan dataset compared to the 2 open-source subsets of SkillSpan our models were fine-tuned on.\nTo get a sense of how these models perform on job ads we might scrape from the internet in the future, we can test them on an example. Lets check out an ad for an SF-based role in the emerging economically lucractive discipline of so-called prompt engineering:\n\nWe can easily load our trained models from the Hugging Face Hub and test them on the full job profile by feeding each sentence to the model individually (similar to how the model was trained). We then print all the sentences where words were labelled. RoBERTa generated the following labels:\n\nfrom transformers import pipeline\n\ntoken_classifier = pipeline(\n    \"token-classification\", model=\"autosyrup/roberta\", tokenizer=\"autosyrup/roberta\",\n    ignore_labels=['O']\n)\n\n\n\nYou will figure out the best methods of prompting our AI to accomplish a wide range of tasks, then document these methods to build up a library of tools and a set of tutorials that allows others to learn prompt engineering, as well as work with high value partners to directly solve their challenges.\n\n\nResponsibilities: Discover, test, and document best practices for a wide range of tasks relevant to our customers.\n\n\nBuild up a library of high quality prompts or prompt chains to accomplish a variety of tasks, with an easy guide to help users search for the one that meets their needs.\n\n\nBuild a set of tutorials and interactive tools that teach the art of prompt engineering to our customers.\n\n\nWork with large enterprise customers on their prompting strategies.\n\n\nAre an excellent communicator, and love teaching technical concepts and creating high quality documentation that helps out others.\n\n\nAre excited to talk to motivated customers and help solve their problems.\n\n\nHave a creative hacker spirit and love solving puzzles.\n\n\n\nHave at least basic programming skills and would be comfortable writing small Python programs.\n\n\nHave an organizational mindset and enjoy building teams from the ground up.\n\n\nYou think holistically and can proactively identify the needs of an organization.\n\n\nMake ambiguous problems clear and identify core principles that can translate across scenarios.\n\n\nYou anticipate unforeseen risks, model out scenarios, and provide actionable guidance to internal stakeholders.\n\n\nThink creatively about the risks and benefits of new technologies, and think beyond past checklists and playbooks.\n\n\nYou stay up-to-date and informed by taking an active interest in emerging research and industry trends.\n\n\nWe can see RoBERTa has identified 24 skills in 15/59 sentences that make up the job ad. The results seem sensible and cover almost all of the skills we might identify in the original ad. We can test the similarly capable JobBERT model to see how it compares with RoBERTa:\n\ntoken_classifier = pipeline(\n    \"token-classification\", model=\"jjzha/jobbert_skill_extraction\", tokenizer=\"jjzha/jobbert_skill_extraction\",\n    ignore_labels=['O']\n)\n\n\n\nYou will figure out the best methods of prompting our AI to accomplish a wide range of tasks, then document these methods to build up a library of tools and a set of tutorials that allows others to learn prompt engineering, as well as work with high value partners to directly solve their challenges.\n\n\nResponsibilities: Discover, test, and document best practices for a wide range of tasks relevant to our customers.\n\n\nBuild up a library of high quality prompts or prompt chains to accomplish a variety of tasks, with an easy guide to help users search for the one that meets their needs.\n\n\nBuild a set of tutorials and interactive tools that teach the art of prompt engineering to our customers.\n\n\nWork with large enterprise customers on their prompting strategies.\n\n\nAre an excellent communicator, and love teaching technical concepts and creating high quality documentation that helps out others.\n\n\nAre excited to talk to motivated customers and help solve their problems.\n\n\nHave a creative hacker spirit and love solving puzzles.\n\n\n\nHave at least basic programming skills and would be comfortable writing small Python programs.\n\n\nHave an organizational mindset and enjoy building teams from the ground up.\n\n\nYou think holistically and can proactively identify the needs of an organization.\n\n\nMake ambiguous problems clear and identify core principles that can translate across scenarios.\n\n\nYou anticipate unforeseen risks, model out scenarios, and provide actionable guidance to internal stakeholders.\n\n\nThink creatively about the risks and benefits of new technologies, and think beyond past checklists and playbooks.\n\n\nAs such, we greatly value communication skills.\n\n\nBoth models label the same 14 sentences out of the 59 that make up the job profile, only differing on several labels. If we include BERT’s inference results, there are at least 26 common spans labelled by 2 of the 3 models:\n\n\n{'Build a set of tutorials and interactive tools',\n 'Build up a library of high quality prompts or prompt chains',\n 'Discover, test, and document best practices',\n 'Make ambiguous problems clear',\n 'Think creatively about the risks and benefits of new technologies',\n 'Work with large enterprise customers',\n 'accomplish a variety of tasks',\n 'anticipate unforeseen risks',\n 'building teams from the ground up',\n 'communicator',\n 'creating high quality documentation',\n 'creative hacker spirit',\n 'helps out others',\n 'identify core principles',\n 'model out scenarios',\n 'organizational mindset',\n 'proactively identify the needs of an organization',\n 'programming',\n 'provide actionable guidance',\n 'solving puzzles',\n 'taking an active interest in emerging research and industry trends',\n 'talk to motivated customers',\n 'teaching technical concepts',\n 'think holistically',\n 'work with high value partners',\n 'writing small Python programs'}\n\n\nThis list of commonly labelled spans suggests it can be advantageous aggregating the inference results from multiple models in a pipeline to filter out some of the lower quality labels (in this case labels like build or the unfinished Think creatively about the risks and benefits of new).\nWhilst auto-encoding transformer models like BERT are theoretically best suited for skills extraction, lets now explore how we can fine-tune and prompt auto-regressive models like GPT-3/GPT-4 into labelling skills.\n\n\n2. Fine-tuning GPT-3\nAt present their are two approaches to guiding OpenAI’s LLMs towards a user-defined task: prompt design and fine-tuning. Prompt design is more accessible; it doesn’t neccesarily require a dataset, data preprocessing or interaction via API. Fine-tuning however can lead to potentially higher quality results and allows us to save costs on inference by removing the need to repeatedly waste tokens explaining the task or desired output format to a model via elaborate or sprawling prompts. Fine-tuning is also pretty straightforward and not very expensive as we will demonstrate.\nCompared to the fine-tuning we previously conducted with BERT, fine-tuning GPT-3 is easier. We don’t need to specify the task, select the best model architecture (other than which version of GPT-3 to fine-tune: davinci, ada, babbage or curie) or install anything (other than the openai python package). We just need to provide a dataset and optional hyper-parameters via the OpenAI API. Through few shot learning LLMs can infer the task we are training them for, which in the case of entity extraction is similar to language transformation tasks.\nTo prepare our dataset for fine-tuning OpenAI recommends we build a .jsonl file with each line containing a sentence from SkillSpan with the sentence as the value for ‘prompt’ and the labels (seperated with line break characters \\n) as the values for ‘completion’ like so:\n{\n    \"prompt\": \"You will be doing this by finding the right partners and building a program to acquire new customers for these markets Develop global partnerships with leading European and South African wineries\\n\\n###\\n\\n\",\n    \"completion\": \" finding the right partners\\nbuilding a program\\naquire new partners\\nDevelop global partnerships END\"\n}\nWe adapt SkillSpan to .jsonl and train Davinci (the most pricey model) on the dataset. Fine-tuning with SkillSpan cost $20 and took just less than 1 hour:\n\nOnce the model is trained, we could easily test on an example sentence, such as Ability to debug issues in a full stack environment, making sure to include some of the formatting quirks OpenAI recommended we included in the training data (like starting prompts with whitespace and ending with \\n\\n####\\n\\n):\n\nopenai.Completion.create(\n    model=\"davinci:ft-autonomy-2023-08-04-19-06-39\",\n    prompt=\" Ability to debug issues in a full stack environment\\n\\n###\\n\\n\",\n    stop=[\" END\"])\n\n&lt;OpenAIObject text_completion id=cmpl-7m5StSLE9WRXTxwUCYllioHchjREs&gt; JSON: {\n  \"id\": \"cmpl-7m5StSLE9WRXTxwUCYllioHchjREs\",\n  \"object\": \"text_completion\",\n  \"created\": 1691695107,\n  \"model\": \"davinci:ft-autonomy-2023-08-04-19-06-39\",\n  \"choices\": [\n    {\n      \"text\": \" debug issues in a full stack environment\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"finish_reason\": \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 13,\n    \"completion_tokens\": 7,\n    \"total_tokens\": 20\n  }\n}\n\n\nIn our testing, fine-tuned GPT-3 correctly labelled debug issues in a full stack environment.\nDespite the model labelling this result correctly, it is still vulnerable to returning text that doesn’t match any substrings within the input sentence. GPT-3 is not deterministic (like BERT) so we could in theory get a different result each time. The fine-tuned model can return results containing capital letters, punctuation and even words that didn’t occur in the input sentence- in other words partially hallucinated skills. We notice this can happen more frequently when setting the optional temperature parameter higher (values between 0.0 and 2.0), which corresponds with the model attempting to be more ‘creative’ in its output at the expense of being deterministic and focussed.\nWe apply post-processing steps on the output text, converting it to a list of labels and then attempting to find the index range in the original sentence where the label occurs. For instances where an exact match cannot be found we use an implementation of the Ratcliff/Obershelp algorithm to perform fuzzy matching. By matching GPT-3’s labels with the original sentences we can actually score the Davinci model using seqeval. We report the following metrics:\n\n\n\n\n\n\n\n\n\n\n\n\nModel/Dataset\nPrecision (HOUSE)\nRecall (HOUSE)\nF1 (HOUSE)\nPrecision (TECH)\nRecall (TECH)\nF1 (TECH)\n\n\n\n\nDavinci (GPT-3)\n46\n34\n39\n48\n40\n44\n\n\n\nIt is surprising and impressive to see GPT-3 is able to perform this task with any competancy, achieving similar precision to BERT, given that the model is inferring the task entirely from the dataset and is approaching token classification as sequence prediction.\nIf we test fine-tuned GPT-3 on the original ‘Prompt Engineer’ job posting we notice the model does identify some of the same labels as the BERT models but also misses a number of key skills and labels incompletely (active, provide, accomplish a and build up are some of the more lacklustre labels):\n\n\nHowever, large language models are a new type of intelligence, and the art of instructing them in a way that delivers the best results is still in its infancy — it’s a hybrid between programming, instructing, and teaching.\n\n\nYou will figure out the best methods of prompting our AI to accomplish a wide range of tasks, then document these methods to build up a library of tools and a set of tutorials that allows others to learn prompt engineering, as well as work with high value partners to directly solve their challenges.\n\n\nResponsibilities: Discover, test, and document best practices for a wide range of tasks relevant to our customers.\n\n\nBuild up a library of high quality prompts or prompt chains to accomplish a variety of tasks, with an easy guide to help users search for the one that meets their needs.\n\n\nBuild a set of tutorials and interactive tools that teach the art of prompt engineering to our customers.\n\n\nWork with large enterprise customers on their prompting strategies.\n\n\nAre an excellent communicator, and love teaching technical concepts and creating high quality documentation that helps out others.\n\n\nAre excited to talk to motivated customers and help solve their problems.\n\n\nHave a creative hacker spirit and love solving puzzles.\n\n\n\nHave at least basic programming skills and would be comfortable writing small Python programs.\n\n\nHave an organizational mindset and enjoy building teams from the ground up.\n\n\nYou think holistically and can proactively identify the needs of an organization.\n\n\nMake ambiguous problems clear and identify core principles that can translate across scenarios.\n\n\nHave a passion for making powerful technology safe and societally beneficial.\n\n\nYou anticipate unforeseen risks, model out scenarios, and provide actionable guidance to internal stakeholders.\n\n\nThink creatively about the risks and benefits of new technologies, and think beyond past checklists and playbooks.\n\n\nYou stay up-to-date and informed by taking an active interest in emerging research and industry trends.\n\n\nAs such, we greatly value communication skills.\n\n\nWe look forward to running more experiments with other GPT-3 models on a range of hyper-parameters and in time GPT-4. We now turn to explore ways in which we can productively prompt OpenAI’s LLMs to extract skills.\n\n\n3. Prompt Design with GPT-3.5 and GPT-4\nPrompt design is an emerging discipline combining programming, instructing, teaching and lots of experimentation. There are infinite ways we could prompt AI to extract skills from text. Within the scope of this experimentation, we explore two approaches:\n\nExtracting substrings from the original text (similar to the other examples)\nInferring skills from the original text without the skills needing to match the original content word for word.\n\nThanks to OpenAI’s API and python library, we can chain together prompts to guide LLMs to output labelled spans with relative ease. The example prompt chain we want to build is two step:\n\nidentify if a sentence from a job profile mentions any skills\nextract skills from the sentence that mentions skills\n\n\n\n\n\n\nThis prompt chain could be represented in the following label_skills_chain function:\n\ndef label_skills_chain(sentence: str, # sentence from job profile \n                 role: str # role title from job profile\n                ) -&gt; list:\n    \"Extracts skills from job profiles\"\n    chat_history = _init_chat_history(sentence, role)\n    contains_skills, contains_skills_chat = _does_sentence_contain_skills(chat_history)  \n    if not contains_skills:\n        return []\n    labelled_skills_chat, skills = _annotate_skills(contains_skills_chat, sentence)\n    return skills\n\ndef _init_chat_history(sentence: str, # sentence from job profile\n                       role: str # role title from job profile\n                      ) -&gt; list[dict]:\n    \"Construct initial chat prompt\"\n    return [\n        {\"role\": \"system\", \"content\": \"You are a professional data annotator tasked with labelling skills within random sentences taken from online job advertisements.\"},\n        {\"role\": \"user\", \"content\": f\"Does the following sentence randomly taken from a job advertisement contain any mention of specific, detailed and relevant skills required for the role of {role}? Answer only 'yes' or 'no' without providing any justification: sentence='{sentence}'\"}\n    ]\n\ndef _does_sentence_contain_skills(chat_history: list # list of prompts and responses\n                                 ) -&gt; Tuple[bool, List[dict]]:\n    \"Check if sentence contains any skills\"\n    response = openai.ChatCompletion.create(\n        model=\"gpt-4\",\n        messages=chat_history,\n        temperature = 0.0\n    )\n    content = response[\"choices\"][0]['message'][\"content\"].lower()\n    if 'yes' in content and 'no' not in content:\n        chat_history.append({'role': 'assistant', 'content': 'yes.'})\n        return True, chat_history\n    else: \n        chat_history.append({'role': 'assistant', 'content': 'no.'})\n        return False, chat_history\n\ndef _annotate_skills(chat_history: list, # \"Construct initial chat prompt\"\n                     sentence: str) -&gt; Tuple[List, List]:\n    \"Label all skills in sentence returning list of skill spans\"\n    annotation_prompt = {\n        \"role\": \"user\",\n        \"content\": f\"Annotate all of the relevant and job-specific skills in the previous sentence. Please return ONLY a Python list containing the substrings within the sentence that mention skills. Avoid skills that are too generic or vague. Here is a reminder of the sentence: {sentence}\"\n    }\n    chat_history.append(annotation_prompt)\n    return _extract_skills_from_response(chat_history)\n\ndef _extract_skills_from_response(chat_history: list # list of prompts and responses\n                                 ) -&gt; Tuple[List, List]:\n    \"Extract skills from the model's response.\"\n    attempt = 0\n    temperature = 0\n    # LLMs hallucinate and return output in myriad formats so we make 3 \n    # attempts to extract list for varying temperatures\n    while attempt &lt; 3:\n        response = openai.ChatCompletion.create(\n            model=\"gpt-4\",\n            messages=chat_history,\n            temperature=temperature\n        )\n        try:\n            chat_history.append({'role': 'assistant', 'content': response['choices'][0]['message'][\"content\"]})\n            return chat_history, ast.literal_eval(response['choices'][0]['message'][\"content\"])\n        except SyntaxError:\n            attempt += 1\n            temperature += 0.2      \n    return [], []\n\n\nlabel_skills_chain(\"You should be able to program in python and cook a mean risotto\", \"Prompt Engineer\")\n\n['program in python', 'cook a mean risotto']\n\n\nLets annotate our favourite ‘Prompt Engineer’ job profile once more:\n\n\nYou will figure out the best methods of prompting our AI to accomplish a wide range of tasks, then document these methods to build up a library of tools and a set of tutorials that allows others to learn prompt engineering, as well as work with high value partners to directly solve their challenges.\n\n\nGiven that the field of prompt-engineering is arguably less than 2 years old, this position is a bit hard to hire for!  As a result, we ask that you share with us a specific prompt engineering project on LLMs that you’re proud of in your application!  Ideally this project should show off a complex and clever prompting architecture or a systematic evaluation of an LLM’s behavior.\n\n\nOur interdisciplinary team has experience across ML, physics, policy, business and product.\n\n\nBuild up a library of high quality prompts or prompt chains to accomplish a variety of tasks, with an easy guide to help users search for the one that meets their needs.\n\n\nBuild a set of tutorials and interactive tools that teach the art of prompt engineering to our customers.\n\n\nHave at least a high level familiarity with the architecture and operation of large language models.\n\n\nAre an excellent communicator, and love teaching technical concepts and creating high quality documentation that helps out others.\n\n\n\nHave at least basic programming skills and would be comfortable writing small Python programs.\n\n\nAs such, we greatly value communication skills.\n\n\nOf course we can also use LLMs to infer skills that don’t exactly match any substrings in the original text. This is a much more flexible approach and opens up potential for more skills to be identified and a greater level of creativity:\n\n\n\n\n\n\n\n\n\nsentence\nlabels\n\n\n\n\n0\nYou will figure out the best methods of prompting our AI to accomplish a wide range of tasks, then document these methods to build up a library of tools and a set of tutorials that allows others to learn prompt engineering, as well as work with high value partners to directly solve their challenges.\n[figuring out best methods of prompting AI, documenting methods, building a library of tools, creating tutorials, working with high value partners, solving challenges]\n\n\n1\nGiven that the field of prompt-engineering is arguably less than 2 years old, this position is a bit hard to hire for! As a result, we ask that you share with us a specific prompt engineering project on LLMs that you’re proud of in your application! Ideally this project should show off a complex and clever prompting architecture or a systematic evaluation of an LLM’s behavior.\n[prompt engineering, working with LLMs, developing complex prompting architecture, systematic evaluation of an LLM’s behavior]\n\n\n2\nOur interdisciplinary team has experience across ML, physics, policy, business and product.\n[ML, physics, policy, business, product]\n\n\n3\nBuild up a library of high quality prompts or prompt chains to accomplish a variety of tasks, with an easy guide to help users search for the one that meets their needs.\n[Building libraries of prompts, Creating prompt chains, Task accomplishment, Guide creation for user assistance, Understanding user needs]\n\n\n4\nBuild a set of tutorials and interactive tools that teach the art of prompt engineering to our customers.\n[Building tutorials, Creating interactive tools, Teaching prompt engineering]\n\n\n5\nHave at least a high level familiarity with the architecture and operation of large language models.\n[high level familiarity with the architecture of large language models, high level familiarity with the operation of large language models]\n\n\n6\nAre an excellent communicator, and love teaching technical concepts and creating high quality documentation that helps out others.\n[excellent communication, teaching technical concepts, creating high quality documentation]\n\n\n7\nHave at least basic programming skills and would be comfortable writing small Python programs.\n[basic programming skills, writing small Python programs]\n\n\n8\nYou anticipate unforeseen risks, model out scenarios, and provide actionable guidance to internal stakeholders.\n[risk anticipation, scenario modelling, providing actionable guidance]\n\n\n9\nAs such, we greatly value communication skills.\n[communication skills]\n\n\n10\nThis research continues many of the directions our team worked on prior to &lt;ORGANISATION&gt;, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\n[GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, Learning from Human Preferences]\n\n\n\n\n\n\n\nGPT-4 has managed to synthesize skills from the text and rewrite them as action orientated, often removing determiners and splitting skills. Build a set of tutorials and interactive tools becomes Building tutorials and Creating interactive tools. We can easily recompose this prompt chain adding checking steps to further filter results. It is likely that we will continue to use a combination transformers for tasks like skill extraction leveraging prompt design and fine-tuning.\n\n\nWeirdos and Misfits Bonus Level 👾👾👾\nWe would be remiss if we didn’t test our fine-tuned models and prompt chains on Dominic Cummings’ vintage job ad.\n\nLets firstly attempt to pass the job profile through Roberta:\n\nfrom transformers import pipeline\n\ntoken_classifier = pipeline(\n    \"token-classification\", model=\"autosyrup/roberta\", tokenizer=\"autosyrup/roberta\",\n    ignore_labels=['O']\n)\n\nweirdo_roberta_results = run_inference_hf(weirdos, token_classifier)\ndisplay_inference_results(weirdo_roberta_results)\n\nOutstanding mathematical skills are essential.\n\n\nYou should be able to explain to other mathematicians, physicists and computer scientists the ideas in such papers, discuss what could be useful for our projects, synthesise ideas for other data scientists, and apply them to practical problems.\n\n\nYou will be working with data scientists, designers and others.\n\n\nYou should a) have an outstanding record at a great university, b) understand conventional economic theories, c) be interested in arguments on the edge of the field — for example, work by physicists on ‘agent-based models’ or by the hedge fund Bridgewater on the failures/limitations of conventional macro theories/prediction, and d) have very strong maths and be interested in working with mathematicians, physicists, and computer scientists.\n\n\nThe ideal candidate might, for example, have a degree in maths and economics, worked at the LHC in one summer, worked with a quant fund another summer, and written software for a YC startup in a third summer!\n\nWe’ve found one of these but want at least one more.\n\n\nWe want to hire some VERY clever young people either straight out of university or recently out with with extreme curiosity and capacity for hard work.\n\n\nManaging a large organisation involves some general skills.\n\n\nWhether it is Coca Cola or Apple, some things are very similar — how to deal with people, how to build great teams and so on.\n\n\nIf you want to figure out what characters around Putin might do, or how international criminal gangs might exploit holes in our border security, you don’t want more Oxbridge English graduates who chat about Lacan at dinner parties with TV producers and spread fake news about fake news.\n\n\nIt’s important when dealing with large organisations to dart around at different levels, not be stuck with formal hierarchies.\n\n\nWe notice the model picks up on spread fake news about fake news as the context may not be clear that whilst this is indeed a (useful) skill, it is undesirable in the opinion of the recruiter. Lets now extend our prompt-chain to include an explanation step where will get GPT-4 to attempt an explanation as to why it has or has not labelled a sentence with skills:\n\n\n\n\n\nThe above prompt chain could be represented as follows:\n\ndef label_and_explain_skills_chain(sentence: str, # sentence from job profile \n                ) -&gt; Tuple[List, str]:\n    \"Extracts skills from job profiles\"\n    chat_history = _init_chat_history(sentence)\n    contains_skills, contains_skills_chat = _does_sentence_contain_skills(chat_history)\n    explanation_chat, explanation = _explain_skills(contains_skills_chat)\n    if not contains_skills:\n        return [], explanation\n    labelled_skills_chat, skills = _annotate_skills(explanation_chat)\n    return skills, explanation\n    \ndef _init_chat_history(sentence: str, # sentence from job profile\n                      ) -&gt; List[dict]:\n    \"Construct initial chat prompt\"\n    return [\n        {\"role\": \"system\", \"content\": \"You are a professional data annotator tasked with labelling skills within random sentences taken from online job advertisements.\"},\n        {\"role\": \"user\", \"content\": f\"Does the following sentence randomly taken from a job advertisement contain any mention of specific, detailed and relevant skills required for a job role? Answer only 'yes' or 'no' without providing any justification: sentence='{sentence}'\"}\n    ]\n    \ndef _explain_skills(chat_history: list # \"Construct initial chat prompt\"\n                   ) -&gt; Tuple[List[dict], str]:\n    \"Force model to explain its labelling decisions\"\n    explanation_prompt = {\n        \"role\": \"user\",\n        \"content\": \"Please explain why you identified or did not identify relevant job skills in this sentence.\"\n    }\n    chat_history.append(explanation_prompt)\n    response = openai.ChatCompletion.create(\n        model=\"gpt-4\",\n        messages=chat_history,\n        temperature = 0.0\n        )\n    explanation = response[\"choices\"][0]['message'][\"content\"]\n    chat_history.append({\"role\": \"assistant\", \"content\": explanation})\n    return chat_history, explanation\n\ndef _annotate_skills(chat_history: list, # \"Construct initial chat prompt\"\n                    ):\n    \"Label all skills in sentence returning list of skill spans\"\n    annotation_prompt = {\n        \"role\": \"user\",\n        \"content\": f\"Please return ONLY a Python list containing the unique skill requirements for a job role that you can infer from this sentence. Only include skills that could be unique, descriptive and essential for a job role. If in doubt, do not include the skill.\"\n    }\n    chat_history.append(annotation_prompt)\n    return _extract_skills_from_response(chat_history)\n\nFor brevity we only run inference on the first ~10 sentences. We hope this demonstrates how simple it is to add additional steps for explainability or checking to an existing prompt chain:\n\n\n\n\n\n\n\n\n\nsentence\nlabels\nexplanation\n\n\n\n\n0\nThere are many brilliant people in the civil service and politics.\n[]\nThe sentence does not mention any specific, detailed, or relevant skills required for a job role. It only makes a general statement about the people in the civil service and politics, without specifying any particular skills or abilities they might have.\n\n\n1\nOver the past five months the No10 political team has been lucky to work with some fantastic officials.\n[]\nThe sentence does not mention any specific, detailed, or relevant skills required for a job role. It only talks about the experience of the No10 political team working with some officials, but it does not specify what skills are needed or were used.\n\n\n2\nBut there are also some profound problems at the core of how the British state makes decisions.\n[]\nThe sentence does not mention any specific, detailed, or relevant skills required for a job role. It is a general statement about decision-making in the British state, but does not specify any particular skills or abilities that a job candidate should possess.\n\n\n3\nThis was seen by pundit-world as a very eccentric view in 2014.\n[]\nThe sentence \"This was seen by pundit-world as a very eccentric view in 2014.\" does not mention any specific, detailed, or relevant skills required for a job role. It seems to be a statement about a viewpoint or opinion, rather than a description of job skills or qualifications.\n\n\n4\nIt is no longer seen as eccentric.\n[]\nThe sentence \"It is no longer seen as eccentric.\" does not mention any specific, detailed, or relevant skills required for a job role. It is a general statement and does not provide any information about job requirements or qualifications.\n\n\n5\nDealing with these deep problems is supported by many great officials, particularly younger ones, though of course there will naturally be many fears — some reasonable, most unreasonable.\n[]\nThe sentence does not mention any specific, detailed, or relevant skills required for a job role. It talks about dealing with problems and mentions officials, but it does not specify what skills are needed to deal with these problems or to be an official.\n\n\n6\nNow there is a confluence of: a) Brexit requires many large changes in policy and in the structure of decision-making, b) some people in government are prepared to take risks to change things a lot, and c) a new government with a significant majority and little need to worry about short-term unpopularity while trying to make rapid progress with long-term problems.\n[]\nThe sentence does not identify any relevant job skills because it is discussing political and governmental circumstances, not specifying any particular skills or abilities needed for a job role.\n\n\n7\nThere is a huge amount of low hanging fruit — trillion dollar bills lying on the street — in the intersection of:\\n\\nthe selection, education and training of people for high performance\\nthe frontiers of the science of prediction\\ndata science, AI and cognitive technologies (e.g Seeing Rooms, ‘authoring tools designed for arguing from evidence’, Tetlock/IARPA prediction tournaments that could easily be extended to consider ‘clusters’ of issues around themes like Brexit to improve policy and project management)\\ncommunication (e.g Cialdini)\\ndecision-making institutions at the apex of government.\n[education and training for high performance, knowledge in the science of prediction, data science, AI and cognitive technologies, communication skills, experience with decision-making institutions at the apex of government]\nThe sentence mentions several relevant job skills such as education and training for high performance, knowledge in the science of prediction, data science, AI and cognitive technologies, communication skills, and experience with decision-making institutions at the apex of government.\n\n\n8\nWe want to hire an unusual set of people with different skills and backgrounds to work in Downing Street with the best officials, some as spads and perhaps some as officials.\n[]\nThe sentence mentions the need for \"different skills and backgrounds\", which implies that the job requires a diverse set of skills. However, it does not specify what these skills are.\n\n\n9\nIf you are already an official and you read this blog and think you fit one of these categories, get in touch.\n[]\nThe sentence does not mention any specific, detailed, or relevant skills required for a job role. It only suggests that the reader should get in touch if they believe they fit into a certain category, but it does not specify what that category is or what skills it might require.\n\n\n10\nThe categories are roughly:\\n\\nData scientists and software developers\\nEconomists\\nPolicy experts\\nProject managers\\nCommunication experts\\nJunior researchers one of whom will also be my personal assistant\\nWeirdos and misfits with odd skills\\nWe want to improve performance and make me much less important — and within a year largely redundant.\n[data analysis, coding, economic analysis, policy analysis, project coordination, project management, effective communication, public relations, research, data collection]\nThe sentence mentions several job roles that inherently require specific skills. For instance, data scientists and software developers need skills in data analysis and coding, economists need skills in economic analysis, policy experts need skills in policy analysis and development, project managers need skills in project coordination and management, communication experts need skills in effective communication and public relations, and junior researchers need skills in research and data collection."
  }
]